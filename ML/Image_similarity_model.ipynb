{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fq-ocNVyedBW"
   },
   "source": [
    "# **Problem Statement:**\n",
    "\n",
    "From an Image dataset we need to find N similar images on a given query image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qZ5FE4_uZjHK"
   },
   "source": [
    "# **Importing Data:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTRgeDTEZpxm"
   },
   "source": [
    "**Loading Data using Curl-WGet:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Uh891FSZ0or"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: doc-10-1c-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.125 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-IN,en;q=0.9,en-GB;q=0.8,en-US;q=0.7,te;q=0.6,ru;q=0.5\" --header=\"Referer: https://drive.google.com/\" --header=\"Cookie: AUTH_4mcuou20mns0bnj0sduihld1f8t3235v_nonce=b9s3il0qbt66q; NID=204=Ays1_cpotq_cm0Nb8bI5w_F9WYRV9rPSgAxwJ4IQJPvPE5l1De1p5T0i_G8ks9GWBNkMcfcVizzpkqjbVmNmOMKYRPQ5VhQYLtQKRevszoS_v_6s2kqMVcPHQanN09BGmeFe45gU5QyrDCYmmtNMqeTsdqgq1PddAdhKBXWEJ-o; _ga=GA1.2.1000151777.1596382410\" --header=\"Connection: keep-alive\" \"https://doc-10-1c-docs.googleusercontent.com/docs/securesc/snqegoftrruv9dh3ufo1tfoti4b5rfsr/lc95gejn67goa7fnhfbpt4tbq0jk9vn7/1597764600000/07496480791912752493/08286913039080874450/1VT-8w1rTT2GCE5IE5zFJPMzv7bqca-Ri?e=download&authuser=0&nonce=b9s3il0qbt66q&user=08286913039080874450&hash=lg9tmmkjjqqfmbdgtdr08daaltq6qpv4\" -c -O 'dataset.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J_y7wPZiaDoV"
   },
   "source": [
    "**Unzipping the folder:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Te1u7STap2BH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!unzip dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sJmvZIq0aKml"
   },
   "source": [
    "*    Using CurlWget method takes couple of seconds to load the data.\n",
    "\n",
    "**Note1:** When the PC gets turned off all the data you loaded through it will get lost. So you need to load the data again when you run the below code snippets.\n",
    "\n",
    "**Note2:** CurlWget gives a .zip file. So we need to unzip the folders before using it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mZTAwyDXaPl3"
   },
   "source": [
    "**Mounting Google Drive:**\n",
    "\n",
    "To access/create files in google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omNl6dJ4aQvp"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20888\\1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9e8ta-sCaU2w"
   },
   "source": [
    "**Loading Dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_kJc0flS5Jq2"
   },
   "outputs": [],
   "source": [
    "# For commands\n",
    "import os\n",
    "os.chdir('/content/')\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# For array manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.util.testing as tm\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import imageio as io\n",
    "from pylab import *\n",
    "from sklearn.manifold import TSNE\n",
    "#For model performance\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.externals import joblib\n",
    "#For model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKbKHo0_akkS"
   },
   "source": [
    "*    I am using tensorflow.keras (2.0 version) throughout this assignment.\n",
    "*    I am doing this case study in google colab. So all the paths will be specified according to colab directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 984,
     "status": "ok",
     "timestamp": 1599830271278,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "5-LgV-c95WV4",
    "outputId": "1d1c4fd7-c8b1-4e16-aed1-3598e590321d"
   },
   "outputs": [],
   "source": [
    "file_path = os.listdir('dataset')\n",
    "print(len(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V5M8mXoAav0H"
   },
   "source": [
    "*    Their are of total 4738 images.\n",
    "*    Since the dataset is small we need to take of model training so that it won't get overfit or underfit.\n",
    "*    Interestingly all the images are in same resolution. (512x512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G3qMbS18a0nv"
   },
   "source": [
    "**Splitting the data into Train & Test sets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ViW-SaoI5bEw"
   },
   "outputs": [],
   "source": [
    "train_files, test_files = train_test_split(file_path, test_size = 0.15)\n",
    "print(len(train_files))\n",
    "print(len(test_files))\n",
    "\n",
    "train_files = pd.DataFrame(train_files,columns=['filepath'])\n",
    "test_files = pd.DataFrame(test_files,columns=['filepath'])\n",
    "#converting into .csv file for future reference.\n",
    "train_files.to_csv('/content/drive/My Drive/train_file.csv')\n",
    "test_files.to_csv('/content/drive/My Drive/test_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UcjVws0GqOka"
   },
   "outputs": [],
   "source": [
    "#loading csv files. \n",
    "train_files = list(pd.read_csv('/content/drive/My Drive/image_similarity/train_file.csv')['filepath'])\n",
    "test_files = list(pd.read_csv('/content/drive/My Drive/image_similarity/test_file.csv')['filepath'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6C8_w3qfa7Ks"
   },
   "source": [
    "*    Taking the file path of all the images and splitting that list into train and test. So that their will be no need of splitting the data again in future and we can access those sets directly by storing it in drive.\n",
    "*    Storing the end result into .csv format so that their will be no data leakage problems in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2244,
     "status": "ok",
     "timestamp": 1599709695533,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "xkSWJvuJq85e",
    "outputId": "22b971e9-7de2-47af-d471-c604d7fcee8d"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('/content/dataset/'+train_files[0])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6wAiGrpOa-9E"
   },
   "source": [
    "**Reading Images:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZToQV69rPhr"
   },
   "outputs": [],
   "source": [
    "def image2array(file_array):\n",
    "\n",
    "    \"\"\"\n",
    "    Reading and Converting images into numpy array by taking path of images.\n",
    "    Arguments:\n",
    "    file_array - (list) - list of file(path) names\n",
    "    Returns:\n",
    "    A numpy array of images. (np.ndarray)\n",
    "    \"\"\"\n",
    "\n",
    "    image_array = []\n",
    "    for path in tqdm(file_array):\n",
    "        img = cv2.imread('/content/dataset/'+path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        image_array.append(np.array(img))\n",
    "    image_array = np.array(image_array)\n",
    "    image_array = image_array.reshape(image_array.shape[0], 224, 224, 3) \n",
    "    image_array = image_array.astype('float32')\n",
    "    image_array /= 255 \n",
    "    return np.array(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148,
     "referenced_widgets": [
      "6e704ed756754a9d95a16a4d90e6cbba",
      "9b5226ea4dce48efab045bf2e697223d",
      "631d7f50d4aa45458341fea370bfdc8b",
      "5b2ad623d4f94ddd89e04b5ea316668e",
      "64811b1d83ca4e53b15241dc51f80466",
      "e4b9f5033dfa47209a1af4640252f323",
      "c5c2e59ee507411388c0c79fcfe400f4",
      "81888ffa35cd448398aaa750939a9660",
      "887df4c1adb0474db7ecae6a4aa8c324",
      "56e6ceb5e7d4469ebe1c869f1fed7fd8",
      "d2d02437e7f74009a5f2d15aeab33ef5",
      "66dd755339e24b7ea79e48ce161f5b4d",
      "72f0003255604d6c819198d08b5af18f",
      "112dbcb401a34345824f4090a6ba666a",
      "9b12adabe29a4e23a772a81a0b6cce7d",
      "e205f345edbf43c7aa8e90d7ecf13f3f"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28511,
     "status": "ok",
     "timestamp": 1599830307819,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "iy_poc_srYLU",
    "outputId": "8fbcaa76-d0b2-487e-f281-f22ab39f8008"
   },
   "outputs": [],
   "source": [
    "train_data = image2array(train_files)\n",
    "print(\"Length of training dataset:\",train_data.shape)\n",
    "test_data = image2array(test_files)\n",
    "print(\"Length of test dataset:\",test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D-eEJMhtbEim"
   },
   "source": [
    "# **Model Architecture & Model Training:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3AmmlsBWrcD0"
   },
   "outputs": [],
   "source": [
    "def encoder_decoder_model():\n",
    "\n",
    "    \"\"\"\n",
    "    Used to build Convolutional Autoencoder model architecture to get compressed image data which is easier to process.\n",
    "    Returns:\n",
    "    Auto encoder model\n",
    "    \"\"\"\n",
    "    #Encoder \n",
    "    model = Sequential(name='Convolutional_AutoEncoder_Model')\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',input_shape=(224, 224, 3),padding='same', name='Encoding_Conv2D_1'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', name='Encoding_MaxPooling2D_1'))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3),strides=1,kernel_regularizer = tf.keras.regularizers.L2(0.001),activation='relu',padding='same', name='Encoding_Conv2D_2'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', name='Encoding_MaxPooling2D_2'))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu',kernel_regularizer= tf.keras.regularizers.L2(0.001), padding='same', name='Encoding_Conv2D_3'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same', name='Encoding_MaxPooling2D_3'))\n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu',kernel_regularizer= tf.keras.regularizers.L2(0.001), padding='same', name='Encoding_Conv2D_4'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,padding='valid', name='Encoding_MaxPooling2D_4'))\n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', name='Encoding_Conv2D_5'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "    \n",
    "    #Decoder\n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001),activation='relu', padding='same', name='Decoding_Conv2D_1'))\n",
    "    model.add(UpSampling2D((2, 2), name='Decoding_Upsamping2D_1'))\n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001), activation='relu', padding='same', name='Decoding_Conv2D_2'))\n",
    "    model.add(UpSampling2D((2, 2), name='Decoding_Upsamping2D_2'))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001), activation='relu', padding='same',name='Decoding_Conv2D_3'))\n",
    "    model.add(UpSampling2D((2, 2),name='Decoding_Upsamping2D_3'))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_regularizer = tf.keras.regularizers.L2(0.001), padding='same',name='Decoding_Conv2D_4'))\n",
    "    model.add(UpSampling2D((2, 2),name='Decoding_Upsamping2D_4'))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer = tf.keras.regularizers.L2(0.001), padding='same',name='Decoding_Conv2D_5'))\n",
    "    model.add(UpSampling2D((2, 2),name='Decoding_Upsamping2D_5'))\n",
    "    model.add(Conv2D(3, kernel_size=(3, 3), padding='same',activation='sigmoid',name='Decoding_Output'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1495,
     "status": "ok",
     "timestamp": 1599823476867,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "HiYXMt7057VQ",
    "outputId": "3de2c2ff-c6c7-48c7-e600-be2daa8a6c3b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = encoder_decoder_model()\n",
    "model.summary()\n",
    "print(\"\\n\")\n",
    "tf.keras.utils.plot_model(model, to_file='/content/drive/My Drive/model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BaNJLGsObOBu"
   },
   "source": [
    "**Hyper parameter Tuning:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1135713,
     "status": "ok",
     "timestamp": 1599834712704,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "pT0QbXWsVCVP",
    "outputId": "a8e4132f-ffcd-412a-bcb0-065575ae0144",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters = {'Adagrad':[0.01,0.001,0.0001,0.00001],'Adam':[0.01,0.001,0.0001,0.00001],'Rmsprop':[0.01,0.001,0.0001,0.00001]}\n",
    "result = []\n",
    "for i in parameters.keys():\n",
    "    print(\"{} as an optimizer:\".format(i))\n",
    "    values = parameters[i]\n",
    "    result_ = []\n",
    "    for learning_rate in values:\n",
    "        print(\"\\t\\tUsing learning_rate: \"+str(learning_rate))\n",
    "        model = encoder_decoder_model()\n",
    "        if i=='Adam':\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "        elif i=='Adagrad':\n",
    "            optimizer = Adagrad(learning_rate=learning_rate)\n",
    "        else:\n",
    "            optimizer = RMSprop(learning_rate=learning_rate)\n",
    "        model.compile(optimizer=optimizer, loss='mse')             # compiling \n",
    "        model.fit(train_data, train_data, epochs=5, batch_size=32,validation_data=(test_data,test_data))  # fitting data\n",
    "        result_.append(model.history.history)           # taking result to judge the best parameters.\n",
    "    print()\n",
    "    result.append(result_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xYwtfDby6Ysl"
   },
   "outputs": [],
   "source": [
    "def plot_(x,y1,y2,row,col,ind,title,xlabel,ylabel,label,isimage=False,color='r'):\n",
    "\n",
    "    \"\"\"\n",
    "    This function is used for plotting images and graphs (Visualization of end results of model training)\n",
    "    Arguments:\n",
    "    x - (np.ndarray or list) - an image array\n",
    "    y1 - (list) - for plotting graph on left side.\n",
    "    y2 - (list) - for plotting graph on right side.\n",
    "    row - (int) - row number of subplot\n",
    "    col - (int) - column number of subplot\n",
    "    ind - (int) - index number of subplot\n",
    "    title - (string) - title of the plot \n",
    "    xlabel - (list) - labels of x axis\n",
    "    ylabel - (list) - labels of y axis\n",
    "    label - (string) - for adding legend in the plot\n",
    "    isimage - (boolean) - True in case of image else False\n",
    "    color - (char) - color of the plot (prefered green for training and red for testing).\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.subplot(row,col,ind)\n",
    "    if isimage:\n",
    "        plt.imshow(x)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        plt.plot(y1,label=label,color='g'); plt.scatter(x,y1,color='g')\n",
    "        if y2!='': plt.plot(y2,color=color,label='validation'); plt.scatter(x,y2,color=color)\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(title); plt.xlabel(xlabel); plt.ylabel(ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3521,
     "status": "ok",
     "timestamp": 1599834759645,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "0ZtbYYPtlQle",
    "outputId": "0b32170f-efee-44db-ce0e-13bc094f207a"
   },
   "outputs": [],
   "source": [
    "min_train = []; min_val = []  \n",
    "rates = list(parameters.keys())\n",
    "epochs = [0,1,2,3,4]\n",
    "for i in result:\n",
    "    train = []; val = []\n",
    "    for j in i:\n",
    "        train.append(min(j['loss'])); val.append(min(j['val_loss']))  # taking minimum loss of each optimizer over all learning rates.\n",
    "    min_train.append(min(train)); min_val.append(min(val))\n",
    "plt.figure(figsize=(20,5))\n",
    "plot_(rates,min_train,min_val,1,2,1,'Minimum loss given by each Optimizer','Optimizer','Loss','training',False,'r')\n",
    "# plotting the result of adam with learning rate = 0.001 .\n",
    "plot_(epochs, result[1][1]['loss'],result[1][1]['val_loss'],1,2,2,'Loss on each epochs using Adam with learning rate = 0.001','Epochs','loss','training',False,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_kXVNWcf3bm"
   },
   "source": [
    "*    After training the model with different optimizers(Adagrad, Adam, Rmsprop), adam giving the least local minimum loss on training with learning rate = 0.001.\n",
    "*    Both training loss and validation loss are almost equal and we can see our model training is not prone to overfitting and underfitting.\n",
    "*    Achieved 0.0093 on five epochs using Adam(0.001)(optimal value).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z8AeKY0AbV5e"
   },
   "source": [
    "**Training the model with Best Optimizer with Best Learning Rate:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 689526,
     "status": "ok",
     "timestamp": 1599835603353,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "mc0ghN4OhnYC",
    "outputId": "67ddb574-b6bb-4db0-c2c3-9f3b8dbae759"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001) \n",
    "model = encoder_decoder_model() \n",
    "model.compile(optimizer=optimizer, loss='mse') \n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min',verbose=1,patience=6,min_delta=0.0001) \n",
    "checkpoint = ModelCheckpoint('/content/drive/My Drive/encoder_model.h5', monitor='val_loss', mode='min', save_best_only=True) \n",
    "model.fit(train_data, train_data, epochs=35, batch_size=32,validation_data=(test_data,test_data),callbacks=[early_stopping,checkpoint]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m944VTKrbdRn"
   },
   "source": [
    "**Plotting loss on each epoch:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1832,
     "status": "ok",
     "timestamp": 1599837496246,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "y8Le6lQtppVT",
    "outputId": "8d8acceb-1e59-463d-d4c0-0d778a115e5d"
   },
   "outputs": [],
   "source": [
    "#model.history.history\n",
    "plt.figure(figsize=(15,5))\n",
    "epochs = [i for i in range(34)]\n",
    "plot_(epochs,loss,'',1,2,1,'Training loss on each epoch','Epoch','Loss','training',False,'g')\n",
    "plot_(epochs,val_loss,'',1,2,2,'validation loss on each epoch','Epoch','Loss','testing',False,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EEstVJXagMLk"
   },
   "source": [
    "*    Their is a strict decrement in the loss for both training and validation.\n",
    "*    After 30 epochs achieved 0.0061 loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXWEDTXXk9tP"
   },
   "source": [
    "**Loading the trained model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqOYSxNdkuwN"
   },
   "outputs": [],
   "source": [
    "model = load_model(\"/content/drive/My Drive/encoder_model.h5\")\n",
    "model.compile(optimizer=optimizer, loss='mse') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "khkg0GzMbiVV"
   },
   "source": [
    "**Model Testing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3023,
     "status": "ok",
     "timestamp": 1599835693956,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "Lb7cYZDNtSmI",
    "outputId": "2b64f265-1eb0-4b5f-d48d-400f4fb65dae"
   },
   "outputs": [],
   "source": [
    "sample_image = train_data[7]\n",
    "sample_image = np.expand_dims(sample_image,axis=0)\n",
    "image = model.predict(sample_image)\n",
    "plot_(sample_image[0,:,:,:],'','',1,2,1,\"Orginal Image\",\"\",\"\",\"\",True)\n",
    "plot_(image[0,:,:],'','',1,2,2,\"Decoded Image\",\"\",\"\",\"\",True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2450,
     "status": "ok",
     "timestamp": 1599835744020,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "IYmLpbhUo3Dq",
    "outputId": "44b9355c-a8f0-4c8e-a5c3-1ae463494776"
   },
   "outputs": [],
   "source": [
    "sample_image = train_data[2396]\n",
    "sample_image = np.expand_dims(sample_image,axis=0)\n",
    "image = model.predict(sample_image)\n",
    "plot_(sample_image[0,:,:,:],'','',1,2,1,\"Orginal Image\",\"\",\"\",\"\",True)\n",
    "plot_(image[0,:,:],'','',1,2,2,\"Decoded Image\",\"\",\"\",\"\",True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ONivM5vpbpMP"
   },
   "source": [
    "**Restoring the Best Model using Model Checkpoint:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1982,
     "status": "ok",
     "timestamp": 1599835845350,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "TDKYs1GSpEBh",
    "outputId": "202ca94a-8a29-48e0-db0f-8fa6d79f45d4"
   },
   "outputs": [],
   "source": [
    "model = load_model('/content/drive/My Drive/encoder_model.h5')\n",
    "sample_image = train_data[15]\n",
    "sample_image = np.expand_dims(sample_image,axis=0)\n",
    "image = model.predict(sample_image)\n",
    "plot_(train_data[15],'','',1,2,1,\"Orginal Image\",\"\",\"\",\"\",True)\n",
    "plot_(image[0,:,:],'','',1,2,2,\"Decoded Image\",\"\",\"\",\"\",True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GCvoFwRlgZoM"
   },
   "source": [
    "*    Restorations seems really satisfactory. Images on the left side are original images whereas images on the right side are restored from compressed representation.\n",
    "*    Decoded image is much flexible and efficient to work rather than working with original image since the compressed representation takes 8 times less space to original image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9aw1TfnPcKq8"
   },
   "source": [
    "# **Feature Extraction:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VE_JwFWcwgao"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def feature_extraction(model, data, layer = 4):\n",
    "\n",
    "    \"\"\"\n",
    "    Creating a function to run the initial layers of the encoder model. (to get feature extraction from any layer of the model)\n",
    "    Arguments:\n",
    "    model - (Auto encoder model) - Trained model\n",
    "    data - (np.ndarray) - list of images to get feature extraction from trained model\n",
    "    layer - (int) - from which layer to take the features(by default = 4)\n",
    "    Returns:\n",
    "    pooled_array - (np.ndarray) - array of extracted features of given images\n",
    "    \"\"\"\n",
    "\n",
    "    encoded = K.function([model.layers[0].input],[model.layers[layer].output])\n",
    "    encoded_array = encoded([data])[0]\n",
    "    pooled_array = encoded_array.max(axis=-1)\n",
    "    return encoded_array\n",
    "encoded = feature_extraction(model,train_data[:10],12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2836,
     "status": "ok",
     "timestamp": 1599838184412,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "YYqZ1MwZv8-R",
    "outputId": "358896e8-88b4-4b31-fc8e-ce5a32968fe1"
   },
   "outputs": [],
   "source": [
    "for index in [2,7,9]:   # 3 random images\n",
    "    plt.figure(figsize=(15,3))\n",
    "    plot_(train_data[index],'','',1,4,1,\"Original Image\",\"\",\"\",'',True)\n",
    "    plot_(encoded[index].mean(axis=-1),'','',1,4,2,\"Encoded Mean\",\"\",\"\",'',True)\n",
    "    plot_(encoded[index].max(axis=-1),'','',1,4,3,\"Encoded Std\",\"\",\"\",'',True)\n",
    "    plot_(encoded[index].std(axis=-1),'','',1,4,4,\"Encoded Std\",\"\",\"\",'',True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQJE84Kwgm5i"
   },
   "source": [
    "*    Extracting features from the 12th layer.\n",
    "*    Dark pixels(yellow) indicates the high activation which helps in differentiating with other images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4732,
     "status": "ok",
     "timestamp": 1599838314828,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "PaL-AgyTyXZq",
    "outputId": "dae9b942-f800-4f7e-9bf8-082a0306bec8"
   },
   "outputs": [],
   "source": [
    "encoded = feature_extraction(model,train_data[:10],9)\n",
    "for index in [2,6,9]:   # 3 random images\n",
    "    plt.figure(figsize=(15,3))\n",
    "    plot_(train_data[index],'','',1,4,1,\"Original Image\",\"\",\"\",'',True)\n",
    "    plot_(encoded[index].mean(axis=-1),'','',1,4,2,\"Encoded Mean\",\"\",\"\",'',True)\n",
    "    plot_(encoded[index].max(axis=-1),'','',1,4,3,\"Encoded Max\",\"\",\"\",'',True)\n",
    "    plot_(encoded[index].std(axis=-1),'','',1,4,4,\"Encoded Std\",\"\",\"\",'',True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "np03G1E2gvgs"
   },
   "source": [
    "Extracting features from the 9th layer.\n",
    "Dark pixels(yellow) indicates the high activation which helps in differentiating with other images.\n",
    "1. High activation on mane of lion.\n",
    "2. Nose and lines on tigers.\n",
    "3. Dots and lines on the nose for cheetah.\n",
    "4. Nose on foxes.\n",
    "These activation helps in label classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vaiayFHpx1lS"
   },
   "outputs": [],
   "source": [
    "def get_batches(data, batch_size=1000):\n",
    "\n",
    "    \"\"\"\n",
    "    Taking batch of images for extraction of images.\n",
    "    Arguments:\n",
    "    data - (np.ndarray or list) - list of image array to get extracted features.\n",
    "    batch_size - (int) - Number of images per each batch\n",
    "    Returns:\n",
    "    list - extracted features of each images\n",
    "    \"\"\"\n",
    "\n",
    "    if len(data) < batch_size:\n",
    "        return [data]\n",
    "    n_batches = len(data) // batch_size\n",
    "    \n",
    "    # If batches fit exactly into the size of df.\n",
    "    if len(data) % batch_size == 0:\n",
    "        return [data[i*batch_size:(i+1)*batch_size] for i in range(n_batches)]   \n",
    "\n",
    "    # If there is a remainder.\n",
    "    else:\n",
    "        return [data[i*batch_size:min((i+1)*batch_size, len(data))] for i in range(n_batches+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4785,
     "status": "ok",
     "timestamp": 1599716215618,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "c4PZvqVhyLR0",
    "outputId": "42ff7514-15ad-4fc4-d216-ca529cc7aa6b"
   },
   "outputs": [],
   "source": [
    "d = np.concatenate([train_data,test_data],axis=0)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_HpcpXMyObK"
   },
   "outputs": [],
   "source": [
    "X_encoded = []\n",
    "i=0\n",
    "# Iterate through the full training set.\n",
    "for batch in get_batches(d, batch_size=300):\n",
    "    i+=1\n",
    "    # This line runs our pooling function on the model for each batch.\n",
    "    X_encoded.append(feature_extraction(model, batch),12)\n",
    "    \n",
    "X_encoded = np.concatenate(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5087,
     "status": "ok",
     "timestamp": 1599716227466,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "X1op3Vt2yVwz",
    "outputId": "61d35e41-7f8a-42f4-b234-21e44ba87865"
   },
   "outputs": [],
   "source": [
    "X_encoded.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1141,
     "status": "ok",
     "timestamp": 1599716230146,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "jZqZUQpSyby7",
    "outputId": "e7f23e89-1468-476d-b6e8-15f74ec497ae"
   },
   "outputs": [],
   "source": [
    "X_encoded_reshape = X_encoded.reshape(X_encoded.shape[0], X_encoded.shape[1]*X_encoded.shape[2]*X_encoded.shape[3])\n",
    "print('Encoded shape:', X_encoded_reshape.shape)\n",
    "np.save('/content/drive/My Drive/X_encoded_compressed.npy',X_encoded_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8001,
     "status": "ok",
     "timestamp": 1599838542344,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "oiZ-4Kyx4Tjt",
    "outputId": "d15a2194-fdef-4bbd-d90a-cee22b638541"
   },
   "outputs": [],
   "source": [
    "X_encoded = np.load('/content/drive/My Drive/X_encoded_compressed.npy')\n",
    "X_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3177,
     "status": "ok",
     "timestamp": 1599839820882,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "HD3oj7O5zy9y",
    "outputId": "c27678ec-eaea-4baa-b06a-52b653f8eda5"
   },
   "outputs": [],
   "source": [
    "lisp=train_files\n",
    "lisp.extend(test_files)\n",
    "print(len(lisp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T7brZmk-clyG"
   },
   "source": [
    "**Dimensionality Reduction through T-SNE:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyuxVaX0JAna"
   },
   "outputs": [],
   "source": [
    "transform = TSNE \n",
    "trans = transform(n_components=2) \n",
    "values = trans.fit_transform(X_encoded_reshape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ZwXDn3_JHkq"
   },
   "outputs": [],
   "source": [
    "def plot_(x,y1,y2,row,col,ind,title,xlabel,ylabel,label,isimage=False,color='b'):\n",
    "\n",
    "    \"\"\"\n",
    "    This function is used for plotting images and graphs (Visualization of end results of model training)\n",
    "    Arguments:\n",
    "    x - (np.ndarray or list) - an image array\n",
    "    y1 - (list) - for plotting graph on left side.\n",
    "    y2 - (list) - for plotting graph on right side.\n",
    "    row - (int) - row number of subplot \n",
    "    col - (int) - column number of subplot\n",
    "    ind - (int) - index number of subplot\n",
    "    title - (string) - title of the plot \n",
    "    xlabel - (list) - labels of x axis\n",
    "    ylabel - (list) - labels of y axis\n",
    "    label - (string) - for adding legend in the plot\n",
    "    isimage - (boolean) - True in case of image else False\n",
    "    color - (char) - color of the plot (prefered green for training and red for testing).\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.subplot(row,col,ind)\n",
    "    if isimage:\n",
    "        plt.imshow(x)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        plt.plot(y1,label=label,color='g'); plt.scatter(x,y1,color='g')\n",
    "        if y2!='': plt.plot(y2,color=color,label='validation'); plt.scatter(x,y2,color=color)\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(title); plt.xlabel(xlabel); plt.ylabel(ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1599845346791,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "gAk7ivYQJT-x",
    "outputId": "aa631344-41b8-4c40-ec1b-7f6e4807d539"
   },
   "outputs": [],
   "source": [
    "lisp=train_files\n",
    "lisp.extend(test_files)\n",
    "print(len(lisp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-jYqMUbcwPP"
   },
   "source": [
    "# **Clustering Image Data:(K-Means)**\n",
    "\n",
    "**Plotting few images of each cluster:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1iJ5v7LsO2xT1QL5OVag77EdYjUJQUL6B"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 305937,
     "status": "ok",
     "timestamp": 1599845656135,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "fXHn8iTQJVEr",
    "outputId": "0a3147cb-2176-42b7-900c-28a71cf7fd00"
   },
   "outputs": [],
   "source": [
    "K = [4,5,6,7]\n",
    "for k in K:\n",
    "    print(\"if Number of clusters: \"+str(k))\n",
    "    kmeans = KMeans(n_clusters = k, random_state=0).fit(X_encoded_reshape)\n",
    "    labels=kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    plt.figure(figsize=(10,5)) \n",
    "    plt.subplot(1,1,1)\n",
    "    plt.scatter(values[:,0], values[:,1], c= kmeans.labels_.astype(float), s=50, alpha=0.5)\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1], c=None, s=50)\n",
    "    plt.show()\n",
    "    for row in range(k): \n",
    "        iter=0\n",
    "        plt.figure(figsize=(13,3))\n",
    "        for i,iterator in enumerate(labels):\n",
    "            if iterator == row:\n",
    "                img = cv2.imread(\"/content/dataset/\"+lisp[i])\n",
    "                img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "                plot_(img,\"\",\"\",1,6,iter+1,\"cluster=\"+str(row),\"\",\"\",\"\",True)\n",
    "                iter+=1\n",
    "            if iter>=5: break\n",
    "        plt.show()\n",
    "    print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v0BJOWRohn3z"
   },
   "source": [
    "with cluster = 4\n",
    "1. lions into first cluster.\n",
    "2. cheetahs into second cluster.\n",
    "3. foxes into third cluster.\n",
    "4. Tigers into fourth cluster.\n",
    "\n",
    "with cluster = 5\n",
    "1. foxes into first cluster.\n",
    "2. cheetahs into second cluster.\n",
    "3. lions into third cluster.\n",
    "4. Tigers into fourth cluster.\n",
    "5. Tiger images with different lighthing conditions and white tigers into fifth cluster.\n",
    "\n",
    "with cluster = 6\n",
    "1. cheetahs into first cluster.\n",
    "2. lions into second cluster.\n",
    "3. snow dogs into third, tigers into fourth cluster.\n",
    "4. leopards into fifth cluster.\n",
    "5. foxes into sixth cluster. (**optimal parameter**)\n",
    "\n",
    "with cluster = 7\n",
    "1. Taking white tigers,cheetahs into separate cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PuaovEXRNrqA"
   },
   "outputs": [],
   "source": [
    "#Training the model with optimial K value (6 in our case)\n",
    "kmeans = KMeans(n_clusters = 6, random_state=0).fit(X_encoded_reshape)\n",
    "labels=kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6_0b8UwGio7A"
   },
   "source": [
    "**Storing the model for future reference:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ru0aTsmjc--3"
   },
   "outputs": [],
   "source": [
    "kmeans_file = '/content/drive/My Drive/kmeans_model.pkl'\n",
    "joblib.dump(kmeans,kmeans_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7llPMefPG7n"
   },
   "outputs": [],
   "source": [
    "clusters_features = []\n",
    "cluster_files=[]\n",
    "for i in [0,1,2,3,4,5]:\n",
    "    i_cluster = []\n",
    "    i_labels=[]\n",
    "    for iter,j in enumerate(kmeans.labels_):\n",
    "        if j==i:\n",
    "            i_cluster.append(X_encoded_reshape[iter])\n",
    "            i_labels.append(lisp[iter])\n",
    "    i_cluster = np.array(i_cluster)\n",
    "    clusters_features.append(i_cluster)\n",
    "    cluster_files.append(i_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2308,
     "status": "ok",
     "timestamp": 1599845818219,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "osj9tSJkPNGl",
    "outputId": "ecf8b690-ba07-47a0-8762-ea77d4dbdd73"
   },
   "outputs": [],
   "source": [
    "labels=[]\n",
    "data=[]\n",
    "files=[]\n",
    "for iter,i in enumerate(clusters_features):\n",
    "    data.extend(i)\n",
    "    labels.extend([iter for i in range(i.shape[0])])\n",
    "    files.extend(cluster_files[iter])\n",
    "print(np.array(labels).shape)\n",
    "print(np.array(data).shape)\n",
    "print(np.array(files).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-HXMETXudSrY"
   },
   "source": [
    "# **Finding Nearest Neighbors(K-NN):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 237833,
     "status": "ok",
     "timestamp": 1599846382303,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "0NgfdJpCPSLt",
    "outputId": "72039639-ff04-42d5-eeae-622fb52ff4f1"
   },
   "outputs": [],
   "source": [
    "for i in [[3,5,7],[9,11,13]]:\n",
    "    plt.figure(figsize=(25,5))\n",
    "    for iter,j in enumerate(i):\n",
    "        n_neighbors = j\n",
    "        X = values  \n",
    "        y = labels\n",
    "        h = .09  # step size in the mesh\n",
    "        cmap_light = ListedColormap(['#FFB6C1', '#AAFFAA', '#AAAAFF','#E6E6FA','#8FBC8F','#DCDCDC'])\n",
    "        cmap_bold = ListedColormap(['#F08080', '#00FF00', '#0000FF','#ADD8E6','#2F4F4F','#808080'])\n",
    "        clf = KNeighborsClassifier(n_neighbors)\n",
    "        clf.fit(X, y)\n",
    "\n",
    "        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1 \n",
    "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1 \n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "        plt.subplot(1,3,iter+1)\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "        # Plot also the training points \n",
    "        plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "        plt.xlim(xx.min(), xx.max())\n",
    "        plt.ylim(yy.min(), yy.max())\n",
    "        plt.title(\"For K = {} as neighbors\".format(j))\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jNj4mWLjshv"
   },
   "source": [
    "**Training the model with optimal hyperparameter:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12984,
     "status": "ok",
     "timestamp": 1599846408962,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "1XxtKpCkPj0c",
    "outputId": "ceca51f2-97ac-4250-9cd0-ed1ba455f245"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9,algorithm='ball_tree',n_jobs=-1)\n",
    "knn.fit(np.array(data),np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VdXCxmSwiyz3"
   },
   "source": [
    "**Storing the model for future reference:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_sT27x6dGUA"
   },
   "outputs": [],
   "source": [
    "knn_file = '/content/drive/My Drive/knn_model.pkl'\n",
    "joblib.dump(knn,knn_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8rsxZ1BQFT2"
   },
   "outputs": [],
   "source": [
    "def results_(query,result):\n",
    "    \n",
    "    \"\"\"\n",
    "    Plotting the N similar images from the dataset with query image.\n",
    "    Arguments:\n",
    "    query - (string) - filename of the query image\n",
    "    result - (list) - filenames of similar images\n",
    "    \"\"\"\n",
    "\n",
    "    def read(img):\n",
    "        image = cv2.imread('/content/dataset/'+img)\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        return image\n",
    "    plt.figure(figsize=(10,5))\n",
    "    if type(query)!=type(30):\n",
    "        plot_(query,\"\",\"\",1,1,1,\"Query Image\",\"\",\"\",\"\",True)\n",
    "    else:\n",
    "        plot_(read(files[query]),\"\",\"\",1,1,1,\"Query Image \"+files[query],\"\",\"\",\"\",True)\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(20,5))\n",
    "    for iter,i in enumerate(result):\n",
    "        plot_(read(files[i]),\"\",\"\",1,len(result),iter+1,files[i],\"\",\"\",\"\",True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rUoyMNp5dfxn"
   },
   "source": [
    "# **Image Similarity Model**\n",
    "\n",
    "**Making predictions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2719,
     "status": "ok",
     "timestamp": 1599846502852,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "fvWNvaVvR9Z3",
    "outputId": "dcab0466-6a67-4984-93c8-e2f7f4360ad2"
   },
   "outputs": [],
   "source": [
    "num = 10 #datapoint\n",
    "res = knn.kneighbors(data[num].reshape(1,-1),return_distance=True,n_neighbors=8)\n",
    "results_(num,list(res[1][0])[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DqVC9V3jSEX-"
   },
   "outputs": [],
   "source": [
    "def predictions(label,N=8,isurl=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Making predictions for the query images and returns N similar images from the dataset.\n",
    "    We can either pass filename or the url for the image.\n",
    "    Arguments:\n",
    "    label - (string) - file name of the query image.\n",
    "    N - (int) - Number of images to be returned\n",
    "    isurl - (string) - if query image is from google is set to True else False(By default = False)\n",
    "    \"\"\"\n",
    "\n",
    "    if isurl:\n",
    "        img = io.imread(label)\n",
    "        img = cv2.resize(img,(224,224))\n",
    "    else:\n",
    "        img_path = '/content/dataset/'+label\n",
    "        img = image.load_img(img_path, target_size=(224,224))\n",
    "    img_data = image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data,axis=0)\n",
    "    img_data = preprocess_input(img_data)\n",
    "    feature = K.function([model.layers[0].input],[model.layers[12].output])\n",
    "    feature = np.array(feature).flatten().reshape(1,-1)\n",
    "    res = knn.kneighbors(feature.reshape(1,-1),return_distance=True,n_neighbors=N)\n",
    "    results_(img,list(res[1][0])[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3769,
     "status": "ok",
     "timestamp": 1599846623917,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "QG6u9QxCSO4C",
    "outputId": "946c7c6b-e64a-451e-c3fb-ca2fa58ec821"
   },
   "outputs": [],
   "source": [
    "query_path = '2427.jpg'\n",
    "predictions(query_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3234,
     "status": "ok",
     "timestamp": 1599846703007,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "KIg0rD7LSdqB",
    "outputId": "ef526af1-fb31-4d8c-b52f-657cc6eeee31"
   },
   "outputs": [],
   "source": [
    "query_path = '4160.jpg'\n",
    "predictions(query_path,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2791,
     "status": "ok",
     "timestamp": 1599847684492,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "nY3HYXGjWgFo",
    "outputId": "f51b36a9-7dea-435d-b731-a1da1c46f460"
   },
   "outputs": [],
   "source": [
    "query_path = '1127.jpg'\n",
    "predictions(query_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2762,
     "status": "ok",
     "timestamp": 1599846747943,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "MzNe5JbKSyxF",
    "outputId": "7f67d372-1768-473e-ed6d-2696ad7ac16c"
   },
   "outputs": [],
   "source": [
    "query_path = '1379.jpg'\n",
    "predictions(query_path,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3525,
     "status": "ok",
     "timestamp": 1599846783829,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "6JqYEjZ7TAPJ",
    "outputId": "94cc0770-1fbb-4b47-fc51-423085c7e589"
   },
   "outputs": [],
   "source": [
    "query_path = '608.jpg'\n",
    "predictions(query_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3045,
     "status": "ok",
     "timestamp": 1599846814308,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "svLY8uRkTIzp",
    "outputId": "58f87b8e-5754-4f20-a75f-f41da5c16f91"
   },
   "outputs": [],
   "source": [
    "query_path = '2550.jpg'\n",
    "predictions(query_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3390,
     "status": "ok",
     "timestamp": 1599846839169,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "RNA0fTwLTQWn",
    "outputId": "949f816f-ca24-4c43-a335-1f146bf3666c"
   },
   "outputs": [],
   "source": [
    "query_path = '167.jpg'\n",
    "predictions(query_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3453,
     "status": "ok",
     "timestamp": 1599846882990,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "rzl9UTn6TWWl",
    "outputId": "860f5f13-ba5d-48c1-9741-b95e518f6d9a"
   },
   "outputs": [],
   "source": [
    "query_path = '543.jpg'\n",
    "predictions(query_path,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlLewKaid2Je"
   },
   "source": [
    "**Testing with google images:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3602,
     "status": "ok",
     "timestamp": 1599847220495,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "MPEkeokvThCb",
    "outputId": "34808f32-2c19-4979-9368-12a235c1d069"
   },
   "outputs": [],
   "source": [
    "import imageio as io\n",
    "query_path = 'https://tse4.mm.bing.net/th?id=OIP.NIMP0bTfhF3898t_ZYLB8QHaE8&pid=Api&P=0&w=248&h=166'\n",
    "predictions(query_path,4,isurl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2706,
     "status": "ok",
     "timestamp": 1599847501961,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "QfJPfWRHTreX",
    "outputId": "b052babe-7f1f-44e2-fcee-16a81bd57b97"
   },
   "outputs": [],
   "source": [
    "query_path = 'https://tse4.mm.bing.net/th?id=OIP.dr7YkzR28BFJerLKJc4cLgHaE7&pid=Api&P=0&w=242&h=162'\n",
    "predictions(query_path,5,isurl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2628,
     "status": "ok",
     "timestamp": 1599847602834,
     "user": {
      "displayName": "saisandhya varapadu",
      "photoUrl": "",
      "userId": "06395658552954856095"
     },
     "user_tz": -330
    },
    "id": "OhL93z8hVUvN",
    "outputId": "4e9b5c67-86c1-4249-ec94-8fcf62942209"
   },
   "outputs": [],
   "source": [
    "query_path = 'https://tse2.mm.bing.net/th?id=OIP.EkSb6SADo3WRj2WFQWTBvgHaFj&pid=Api&P=0&w=216&h=163'\n",
    "predictions(query_path,6,isurl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nH5LJwm_WOCF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOqdfLcVnl6FA1zKPnx2YHm",
   "mount_file_id": "1fytYFBhJFodkf0o5lKzJXt29oN1fOVET",
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "112dbcb401a34345824f4090a6ba666a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56e6ceb5e7d4469ebe1c869f1fed7fd8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b2ad623d4f94ddd89e04b5ea316668e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81888ffa35cd448398aaa750939a9660",
      "placeholder": "",
      "style": "IPY_MODEL_c5c2e59ee507411388c0c79fcfe400f4",
      "value": " 4027/4027 [00:27&lt;00:00, 147.55it/s]"
     }
    },
    "631d7f50d4aa45458341fea370bfdc8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4b9f5033dfa47209a1af4640252f323",
      "max": 4027,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_64811b1d83ca4e53b15241dc51f80466",
      "value": 4027
     }
    },
    "64811b1d83ca4e53b15241dc51f80466": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "66dd755339e24b7ea79e48ce161f5b4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e205f345edbf43c7aa8e90d7ecf13f3f",
      "placeholder": "",
      "style": "IPY_MODEL_9b12adabe29a4e23a772a81a0b6cce7d",
      "value": " 711/711 [00:05&lt;00:00, 130.48it/s]"
     }
    },
    "6e704ed756754a9d95a16a4d90e6cbba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_631d7f50d4aa45458341fea370bfdc8b",
       "IPY_MODEL_5b2ad623d4f94ddd89e04b5ea316668e"
      ],
      "layout": "IPY_MODEL_9b5226ea4dce48efab045bf2e697223d"
     }
    },
    "72f0003255604d6c819198d08b5af18f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "81888ffa35cd448398aaa750939a9660": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "887df4c1adb0474db7ecae6a4aa8c324": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d2d02437e7f74009a5f2d15aeab33ef5",
       "IPY_MODEL_66dd755339e24b7ea79e48ce161f5b4d"
      ],
      "layout": "IPY_MODEL_56e6ceb5e7d4469ebe1c869f1fed7fd8"
     }
    },
    "9b12adabe29a4e23a772a81a0b6cce7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b5226ea4dce48efab045bf2e697223d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5c2e59ee507411388c0c79fcfe400f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2d02437e7f74009a5f2d15aeab33ef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_112dbcb401a34345824f4090a6ba666a",
      "max": 711,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_72f0003255604d6c819198d08b5af18f",
      "value": 711
     }
    },
    "e205f345edbf43c7aa8e90d7ecf13f3f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4b9f5033dfa47209a1af4640252f323": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
